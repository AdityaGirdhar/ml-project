{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data_no_onehot = pd.read_csv('../data/all.csv')\n",
    "data_onehot = pd.read_csv('../data/all_with_onehot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>MealType</th>\n",
       "      <th>Paytm+Cash</th>\n",
       "      <th>Coupons</th>\n",
       "      <th>SemType</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>CouponsMand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3</td>\n",
       "      <td>BreakFast</td>\n",
       "      <td>186.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Acad</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>293.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>Acad</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3</td>\n",
       "      <td>EveningSnacks</td>\n",
       "      <td>37.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Acad</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>113.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>Acad</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>4</td>\n",
       "      <td>BreakFast</td>\n",
       "      <td>100.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>Acad</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Weekday       MealType  Paytm+Cash  Coupons SemType  Holiday  \\\n",
       "0  2022-09-01        3      BreakFast       186.0    117.0    Acad        0   \n",
       "1  2022-09-01        3          Lunch       293.0    217.0    Acad        0   \n",
       "2  2022-09-01        3  EveningSnacks        37.0    139.0    Acad        0   \n",
       "3  2022-09-01        3         Dinner       113.0    220.0    Acad        0   \n",
       "4  2022-09-02        4      BreakFast       100.0    236.0    Acad        0   \n",
       "\n",
       "   CouponsMand  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the dataset\n",
    "def preprocess(data, to_onehot=True, to_drop_vacation=False):\n",
    "    if not to_onehot:\n",
    "        data = data.dropna()\n",
    "        \n",
    "    # Converting the date column to datetime\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "    # Adding day, dayofweek, month and year columns\n",
    "    data['Day'] = pd.DatetimeIndex(data['Date']).day\n",
    "    data['Month'] = pd.DatetimeIndex(data['Date']).month\n",
    "    data['Year'] = pd.DatetimeIndex(data['Date']).year\n",
    "\n",
    "    # Scaling the data\n",
    "    # to_normalize = ['Day']\n",
    "    # scaler = MinMaxScaler()\n",
    "    # data[to_normalize] = scaler.fit_transform(data[to_normalize])\n",
    "\n",
    "    # to_normalize = ['Holiday']\n",
    "    # scaler = StandardScaler()\n",
    "    # data[to_normalize] = scaler.fit_transform(data[to_normalize])\n",
    "\n",
    "    # Encoding the categorical data\n",
    "    if to_onehot:\n",
    "        categorical_features = ['Weekday', 'Month', 'Year', 'MealType', 'SemType']\n",
    "        data = pd.get_dummies(data, columns=categorical_features)\n",
    "    else:\n",
    "        # Using label encoding\n",
    "        categorical_features = ['MealType', 'SemType']\n",
    "        for feature in categorical_features:\n",
    "            data[feature] = data[feature].astype('category')\n",
    "            data[feature] = data[feature].cat.codes\n",
    "\n",
    "    # Dropping vacations (if required)\n",
    "    if to_drop_vacation:\n",
    "        data = data[data['Semtype_Vacation'] == 0]\n",
    "\n",
    "    # Splitting into X and y\n",
    "    X = data.drop(columns=['Paytm+Cash', 'Coupons'])\n",
    "    y_paytm = data['Paytm+Cash']\n",
    "    y_coupons = data['Coupons']\n",
    "    y_total = data['Paytm+Cash'] + data['Coupons']\n",
    "\n",
    "    return X, y_paytm, y_coupons, y_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajad\\AppData\\Local\\Temp\\ipykernel_18472\\4106291311.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Date'] = pd.to_datetime(data['Date'])\n",
      "C:\\Users\\rajad\\AppData\\Local\\Temp\\ipykernel_18472\\4106291311.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Day'] = pd.DatetimeIndex(data['Date']).day\n",
      "C:\\Users\\rajad\\AppData\\Local\\Temp\\ipykernel_18472\\4106291311.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Month'] = pd.DatetimeIndex(data['Date']).month\n",
      "C:\\Users\\rajad\\AppData\\Local\\Temp\\ipykernel_18472\\4106291311.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Year'] = pd.DatetimeIndex(data['Date']).year\n",
      "C:\\Users\\rajad\\AppData\\Local\\Temp\\ipykernel_18472\\4106291311.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[feature].astype('category')\n",
      "C:\\Users\\rajad\\AppData\\Local\\Temp\\ipykernel_18472\\4106291311.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[feature].cat.codes\n",
      "C:\\Users\\rajad\\AppData\\Local\\Temp\\ipykernel_18472\\4106291311.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[feature].astype('category')\n",
      "C:\\Users\\rajad\\AppData\\Local\\Temp\\ipykernel_18472\\4106291311.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[feature].cat.codes\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into train and test sets (with vacations)\n",
    "X_no_onehot, y_paytm_no_onehot, y_coupons_no_onehot, y_total_no_onehot = preprocess(data_no_onehot, to_onehot=False)\n",
    "X_onehot, y_paytm_onehot, y_coupons_onehot, y_total_onehot = preprocess(data_onehot)\n",
    "\n",
    "# cutoff at 2023-08-31 for no onehot\n",
    "X_train_no_onehot = X_no_onehot[X_no_onehot['Date'] <= '2023-08-31']\n",
    "X_test_no_onehot = X_no_onehot[X_no_onehot['Date'] > '2023-08-31']\n",
    "y_paytm_train_no_onehot = y_paytm_no_onehot[X_no_onehot['Date'] <= '2023-08-31']\n",
    "y_paytm_test_no_onehot = y_paytm_no_onehot[X_no_onehot['Date'] > '2023-08-31']\n",
    "y_coupons_train_no_onehot = y_coupons_no_onehot[X_no_onehot['Date'] <= '2023-08-31']\n",
    "y_coupons_test_no_onehot = y_coupons_no_onehot[X_no_onehot['Date'] > '2023-08-31']\n",
    "y_total_train_no_onehot = y_total_no_onehot[X_no_onehot['Date'] <= '2023-08-31']\n",
    "y_total_test_no_onehot = y_total_no_onehot[X_no_onehot['Date'] > '2023-08-31']\n",
    "\n",
    "# cutoff at 2023-08-31 for onehot\n",
    "X_train_onehot = X_onehot[X_onehot['Date'] <= '2023-08-31']\n",
    "X_test_onehot = X_onehot[X_onehot['Date'] > '2023-08-31']\n",
    "y_paytm_train_onehot = y_paytm_onehot[X_onehot['Date'] <= '2023-08-31']\n",
    "y_paytm_test_onehot = y_paytm_onehot[X_onehot['Date'] > '2023-08-31']\n",
    "y_coupons_train_onehot = y_coupons_onehot[X_onehot['Date'] <= '2023-08-31']\n",
    "y_coupons_test_onehot = y_coupons_onehot[X_onehot['Date'] > '2023-08-31']\n",
    "y_total_train_onehot = y_total_onehot[X_onehot['Date'] <= '2023-08-31']\n",
    "y_total_test_onehot = y_total_onehot[X_onehot['Date'] > '2023-08-31']\n",
    "\n",
    "# Drop the date column\n",
    "X_train_no_onehot = X_train_no_onehot.drop(columns=['Date'])\n",
    "X_test_no_onehot = X_test_no_onehot.drop(columns=['Date'])\n",
    "X_train_onehot = X_train_onehot.drop(columns=['Date'])\n",
    "X_test_onehot = X_test_onehot.drop(columns=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for grid search\n",
    "parameters = {\n",
    "    'n_estimators': [100, 250, 500, 750, 1000],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['sqrt', 'log2', 25, 50, 100, None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_train, y_train, X_test, y_test, parameters):\n",
    "   # Grid search for paytm+cash using for loops\n",
    "    best_parameters = {}\n",
    "\n",
    "    for n_estimators in parameters['n_estimators']:\n",
    "        for max_depth in parameters['max_depth']:\n",
    "            for min_samples_split in parameters['min_samples_split']:\n",
    "                for min_samples_leaf in parameters['min_samples_leaf']:\n",
    "                    for max_features in parameters['max_features']:\n",
    "                        rfr = RandomForestRegressor(n_estimators=n_estimators, \n",
    "                                                    max_depth=max_depth, \n",
    "                                                    min_samples_split=min_samples_split, \n",
    "                                                    min_samples_leaf=min_samples_leaf,\n",
    "                                                    max_features=max_features, \n",
    "                                                    random_state=42)\n",
    "                        rfr.fit(X_train, y_train)\n",
    "                        y_pred = rfr.predict(X_test)\n",
    "                        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                        r2 = r2_score(y_test, y_pred)\n",
    "                        best_parameters[(rmse, r2)] = (n_estimators, max_depth, min_samples_split, min_samples_leaf)\n",
    "\n",
    "    # Printing the best parameters with scores\n",
    "    best_parameters = sorted(best_parameters.items(), key=lambda x: -1 * x[0][1])\n",
    "    print('Best parameters:')\n",
    "    print('RMSE:', best_parameters[0][0][0])\n",
    "    print('R2:', best_parameters[0][0][1])\n",
    "    print('Parameters:', best_parameters[0][1])\n",
    "\n",
    "    return best_parameters[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rajad\\OneDrive\\Desktop\\vscode files\\ML Project\\models\\random_forest.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rajad/OneDrive/Desktop/vscode%20files/ML%20Project/models/random_forest.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Grid search for paytm+cash using onehot\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rajad/OneDrive/Desktop/vscode%20files/ML%20Project/models/random_forest.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m best_parameters_paytm_onehot \u001b[39m=\u001b[39m grid_search(X_train_onehot, y_paytm_train_onehot, X_test_onehot, y_paytm_test_onehot, parameters)\n",
      "\u001b[1;32mc:\\Users\\rajad\\OneDrive\\Desktop\\vscode files\\ML Project\\models\\random_forest.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rajad/OneDrive/Desktop/vscode%20files/ML%20Project/models/random_forest.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m max_features \u001b[39min\u001b[39;00m parameters[\u001b[39m'\u001b[39m\u001b[39mmax_features\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rajad/OneDrive/Desktop/vscode%20files/ML%20Project/models/random_forest.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     rfr \u001b[39m=\u001b[39m RandomForestRegressor(n_estimators\u001b[39m=\u001b[39mn_estimators, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rajad/OneDrive/Desktop/vscode%20files/ML%20Project/models/random_forest.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                 max_depth\u001b[39m=\u001b[39mmax_depth, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rajad/OneDrive/Desktop/vscode%20files/ML%20Project/models/random_forest.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                                 min_samples_split\u001b[39m=\u001b[39mmin_samples_split, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rajad/OneDrive/Desktop/vscode%20files/ML%20Project/models/random_forest.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                                 min_samples_leaf\u001b[39m=\u001b[39mmin_samples_leaf,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rajad/OneDrive/Desktop/vscode%20files/ML%20Project/models/random_forest.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                                 max_features\u001b[39m=\u001b[39mmax_features, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rajad/OneDrive/Desktop/vscode%20files/ML%20Project/models/random_forest.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                                 random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rajad/OneDrive/Desktop/vscode%20files/ML%20Project/models/random_forest.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     rfr\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rajad/OneDrive/Desktop/vscode%20files/ML%20Project/models/random_forest.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m rfr\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rajad/OneDrive/Desktop/vscode%20files/ML%20Project/models/random_forest.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     rmse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(mean_squared_error(y_test, y_pred))\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1052\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    783\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\tree\\_classes.py:308\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    303\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of labels=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m does not match number of samples=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(y), n_samples)\n\u001b[0;32m    305\u001b[0m     )\n\u001b[0;32m    307\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 308\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, DOUBLE)\n\u001b[0;32m    310\u001b[0m \u001b[39mif\u001b[39;00m expanded_class_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1766\u001b[0m, in \u001b[0;36m_check_sample_weight\u001b[1;34m(sample_weight, X, dtype, copy, only_non_negative)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1765\u001b[0m     dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1766\u001b[0m sample_weight \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1767\u001b[0m     sample_weight,\n\u001b[0;32m   1768\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1769\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1770\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1771\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1772\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1773\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msample_weight\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1774\u001b[0m )\n\u001b[0;32m   1775\u001b[0m \u001b[39mif\u001b[39;00m sample_weight\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1776\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSample weights must be 1D array or scalar\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m# error message.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(over\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 122\u001b[0m     first_pass_isfinite \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39misfinite(xp\u001b[39m.\u001b[39;49msum(X))\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2298\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2295\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   2296\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m-> 2298\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[0;32m   2299\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\Users\\rajad\\miniconda3\\envs\\tf\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid search for paytm+cash using onehot\n",
    "best_parameters_paytm_onehot = grid_search(X_train_onehot, y_paytm_train_onehot, X_test_onehot, y_paytm_test_onehot, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for paytm_cash without using onehot\n",
    "best_parameters_paytm_no_onehot = grid_search(X_train_no_onehot, y_paytm_train_no_onehot, X_test_no_onehot, y_paytm_test_no_onehot, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for coupons using onehot\n",
    "best_parameters_coupons_onehot = grid_search(X_train_onehot, y_coupons_train_onehot, X_test_onehot, y_coupons_test_onehot, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for coupons without using onehot\n",
    "best_parameters_coupons_no_onehot = grid_search(X_train_no_onehot, y_coupons_train_no_onehot, X_test_no_onehot, y_coupons_test_no_onehot, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for total using onehot\n",
    "best_parameters_total_onehot = grid_search(X_train_onehot, y_total_train_onehot, X_test_onehot, y_total_test_onehot, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for total without using onehot\n",
    "best_parameters_total_no_onehot = grid_search(X_train_no_onehot, y_total_train_no_onehot, X_test_no_onehot, y_total_test_no_onehot, parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
