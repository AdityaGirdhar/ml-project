{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data_no_onehot = pd.read_csv('../data/all.csv')\n",
    "data_onehot = pd.read_csv('../data/all_with_onehot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>MealType</th>\n",
       "      <th>Paytm+Cash</th>\n",
       "      <th>Coupons</th>\n",
       "      <th>SemType</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>CouponsMand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3</td>\n",
       "      <td>BreakFast</td>\n",
       "      <td>186.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Acad</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>293.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>Acad</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3</td>\n",
       "      <td>EveningSnacks</td>\n",
       "      <td>37.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Acad</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>113.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>Acad</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>4</td>\n",
       "      <td>BreakFast</td>\n",
       "      <td>100.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>Acad</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Weekday       MealType  Paytm+Cash  Coupons SemType  Holiday  \\\n",
       "0  2022-09-01        3      BreakFast       186.0    117.0    Acad        0   \n",
       "1  2022-09-01        3          Lunch       293.0    217.0    Acad        0   \n",
       "2  2022-09-01        3  EveningSnacks        37.0    139.0    Acad        0   \n",
       "3  2022-09-01        3         Dinner       113.0    220.0    Acad        0   \n",
       "4  2022-09-02        4      BreakFast       100.0    236.0    Acad        0   \n",
       "\n",
       "   CouponsMand  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the dataset\n",
    "def preprocess(data, to_onehot=True, to_drop_vacation=False):\n",
    "    if not to_onehot:\n",
    "        data = data.dropna()\n",
    "        \n",
    "    # Converting the date column to datetime\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "    # Adding day, dayofweek, month and year columns\n",
    "    data['Day'] = pd.DatetimeIndex(data['Date']).day\n",
    "    data['Month'] = pd.DatetimeIndex(data['Date']).month\n",
    "    data['Year'] = pd.DatetimeIndex(data['Date']).year\n",
    "\n",
    "    # Scaling the data\n",
    "    to_normalize = ['Day']\n",
    "    scaler = MinMaxScaler()\n",
    "    data[to_normalize] = scaler.fit_transform(data[to_normalize])\n",
    "\n",
    "    to_normalize = ['Holiday']\n",
    "    scaler = StandardScaler()\n",
    "    data[to_normalize] = scaler.fit_transform(data[to_normalize])\n",
    "\n",
    "    # Encoding the categorical data\n",
    "    if to_onehot:\n",
    "        categorical_features = ['Weekday', 'Month', 'Year', 'MealType', 'SemType']\n",
    "        data = pd.get_dummies(data, columns=categorical_features)\n",
    "    else:\n",
    "        # Using label encoding\n",
    "        categorical_features = ['MealType', 'SemType']\n",
    "        for feature in categorical_features:\n",
    "            data[feature] = data[feature].astype('category')\n",
    "            data[feature] = data[feature].cat.codes\n",
    "\n",
    "    # Dropping vacations (if required)\n",
    "    if to_drop_vacation:\n",
    "        data = data[data['Semtype_Vacation'] == 0]\n",
    "\n",
    "    # Splitting into X and y\n",
    "    X = data.drop(columns=['Paytm+Cash', 'Coupons'])\n",
    "    y_paytm = data['Paytm+Cash']\n",
    "    y_coupons = data['Coupons']\n",
    "    y_total = data['Paytm+Cash'] + data['Coupons']\n",
    "\n",
    "    return X, y_paytm, y_coupons, y_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/w8t5vd_11zs7s9jlct5ksrfr0000gn/T/ipykernel_22711/2238380120.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Date'] = pd.to_datetime(data['Date'])\n",
      "/var/folders/4d/w8t5vd_11zs7s9jlct5ksrfr0000gn/T/ipykernel_22711/2238380120.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Day'] = pd.DatetimeIndex(data['Date']).day\n",
      "/var/folders/4d/w8t5vd_11zs7s9jlct5ksrfr0000gn/T/ipykernel_22711/2238380120.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Month'] = pd.DatetimeIndex(data['Date']).month\n",
      "/var/folders/4d/w8t5vd_11zs7s9jlct5ksrfr0000gn/T/ipykernel_22711/2238380120.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Year'] = pd.DatetimeIndex(data['Date']).year\n",
      "/var/folders/4d/w8t5vd_11zs7s9jlct5ksrfr0000gn/T/ipykernel_22711/2238380120.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[to_normalize] = scaler.fit_transform(data[to_normalize])\n",
      "/var/folders/4d/w8t5vd_11zs7s9jlct5ksrfr0000gn/T/ipykernel_22711/2238380120.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[to_normalize] = scaler.fit_transform(data[to_normalize])\n",
      "/var/folders/4d/w8t5vd_11zs7s9jlct5ksrfr0000gn/T/ipykernel_22711/2238380120.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[feature].astype('category')\n",
      "/var/folders/4d/w8t5vd_11zs7s9jlct5ksrfr0000gn/T/ipykernel_22711/2238380120.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[feature].cat.codes\n",
      "/var/folders/4d/w8t5vd_11zs7s9jlct5ksrfr0000gn/T/ipykernel_22711/2238380120.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[feature].astype('category')\n",
      "/var/folders/4d/w8t5vd_11zs7s9jlct5ksrfr0000gn/T/ipykernel_22711/2238380120.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[feature].cat.codes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekday</th>\n",
       "      <th>MealType</th>\n",
       "      <th>SemType</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>CouponsMand</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.395613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.395613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.395613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.395613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.395613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.395613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.395613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.395613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.247439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.247439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weekday  MealType  SemType   Holiday  CouponsMand       Day  Month  Year\n",
       "0        3         0        0 -0.395613          0.0  0.000000      9  2022\n",
       "1        3         3        0 -0.395613          0.0  0.000000      9  2022\n",
       "2        3         2        0 -0.395613          0.0  0.000000      9  2022\n",
       "3        3         1        0 -0.395613          0.0  0.000000      9  2022\n",
       "4        4         0        0 -0.395613          0.0  0.033333      9  2022\n",
       "5        4         3        0 -0.395613          0.0  0.033333      9  2022\n",
       "6        4         2        0 -0.395613          0.0  0.033333      9  2022\n",
       "7        4         1        0 -0.395613          0.0  0.033333      9  2022\n",
       "8        5         0        0 -0.247439          0.0  0.066667      9  2022\n",
       "9        5         3        0 -0.247439          0.0  0.066667      9  2022"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into train and test sets (with vacations)\n",
    "X_no_onehot, y_paytm_no_onehot, y_coupons_no_onehot, y_total_no_onehot = preprocess(data_no_onehot, to_onehot=False)\n",
    "X_onehot, y_paytm_onehot, y_coupons_onehot, y_total_onehot = preprocess(data_onehot)\n",
    "\n",
    "# cutoff at 2023-08-31 for no onehot\n",
    "X_train_no_onehot = X_no_onehot[X_no_onehot['Date'] <= '2023-08-31']\n",
    "X_test_no_onehot = X_no_onehot[X_no_onehot['Date'] > '2023-08-31']\n",
    "y_paytm_train_no_onehot = y_paytm_no_onehot[X_no_onehot['Date'] <= '2023-08-31']\n",
    "y_paytm_test_no_onehot = y_paytm_no_onehot[X_no_onehot['Date'] > '2023-08-31']\n",
    "y_coupons_train_no_onehot = y_coupons_no_onehot[X_no_onehot['Date'] <= '2023-08-31']\n",
    "y_coupons_test_no_onehot = y_coupons_no_onehot[X_no_onehot['Date'] > '2023-08-31']\n",
    "y_total_train_no_onehot = y_total_no_onehot[X_no_onehot['Date'] <= '2023-08-31']\n",
    "y_total_test_no_onehot = y_total_no_onehot[X_no_onehot['Date'] > '2023-08-31']\n",
    "\n",
    "# cutoff at 2023-08-31 for onehot\n",
    "X_train_onehot = X_onehot[X_onehot['Date'] <= '2023-08-31']\n",
    "X_test_onehot = X_onehot[X_onehot['Date'] > '2023-08-31']\n",
    "y_paytm_train_onehot = y_paytm_onehot[X_onehot['Date'] <= '2023-08-31']\n",
    "y_paytm_test_onehot = y_paytm_onehot[X_onehot['Date'] > '2023-08-31']\n",
    "y_coupons_train_onehot = y_coupons_onehot[X_onehot['Date'] <= '2023-08-31']\n",
    "y_coupons_test_onehot = y_coupons_onehot[X_onehot['Date'] > '2023-08-31']\n",
    "y_total_train_onehot = y_total_onehot[X_onehot['Date'] <= '2023-08-31']\n",
    "y_total_test_onehot = y_total_onehot[X_onehot['Date'] > '2023-08-31']\n",
    "\n",
    "# Drop the date column\n",
    "X_train_no_onehot = X_train_no_onehot.drop(columns=['Date'])\n",
    "X_test_no_onehot = X_test_no_onehot.drop(columns=['Date'])\n",
    "X_train_onehot = X_train_onehot.drop(columns=['Date'])\n",
    "X_test_onehot = X_test_onehot.drop(columns=['Date'])\n",
    "\n",
    "X_train_no_onehot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an MLP Regressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# MLP for Paytm+Cash\n",
    "mlp_paytm = MLPRegressor()\n",
    "\n",
    "# MLP for Coupons\n",
    "mlp_coupons = MLPRegressor()\n",
    "\n",
    "# MLP for Total\n",
    "mlp_total = MLPRegressor()\n",
    "\n",
    "# Grid search for Paytm+Cash\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(200, 200), (200, 100), (100, 100), (50, 50), (300, 300), (300, 200), (400, 400)],\n",
    "    'activation': [\n",
    "        'relu',\n",
    "        # 'logistic'\n",
    "        ],\n",
    "    'solver': [\n",
    "        'adam', \n",
    "        # 'sgd'\n",
    "        ],\n",
    "    'learning_rate': [\n",
    "        # 'constant',\n",
    "        'adaptive'\n",
    "    ],\n",
    "    'max_iter': [1500],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "\n",
    "def grid_search(X_train, y_train, X_test, y_test, parameters):\n",
    "   # Grid search for paytm+cash using for loops\n",
    "    best_parameters = {}\n",
    "\n",
    "    for hidden_layer_sizes in parameters['hidden_layer_sizes']:\n",
    "        for activation in parameters['activation']:\n",
    "            for solver in parameters['solver']:\n",
    "                for learning_rate in parameters['learning_rate']:\n",
    "                    for max_iter in parameters['max_iter']:\n",
    "                        for alpha in parameters['alpha']:\n",
    "                            print(\"Parameters:\", hidden_layer_sizes, activation, solver, learning_rate, max_iter, alpha)\n",
    "                            mlp = MLPRegressor(\n",
    "                                hidden_layer_sizes=hidden_layer_sizes, \n",
    "                                activation=activation, solver=solver, \n",
    "                                learning_rate=learning_rate, \n",
    "                                max_iter=max_iter,\n",
    "                                alpha=alpha\n",
    "                                )\n",
    "                            mlp.fit(X_train, y_train)\n",
    "                            # training error:\n",
    "                            y_pred = mlp.predict(X_train)\n",
    "                            rmse_train = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "                            r2_train = r2_score(y_train, y_pred)\n",
    "                            print('Training error:' + str(rmse_train) + ' ' + str(r2_train))\n",
    "                            # testing error:\n",
    "                            y_pred = mlp.predict(X_test)\n",
    "                            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                            r2 = r2_score(y_test, y_pred)\n",
    "                            print('Testing error:' + str(rmse) + ' ' + str(r2) + '\\n')\n",
    "                            best_parameters[(rmse, r2)] = (hidden_layer_sizes, activation, solver, learning_rate, max_iter)\n",
    "        \n",
    "    # Printing the best parameters with scores\n",
    "    best_parameters = sorted(best_parameters.items(), key=lambda x: -1 * x[0][1])\n",
    "    print('Best parameters:')\n",
    "    print('RMSE:', best_parameters[0][0][0])\n",
    "    print('R2:', best_parameters[0][0][1])\n",
    "    print('Parameters:', best_parameters[0][1])\n",
    "\n",
    "    return best_parameters[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: (200, 200) relu adam adaptive 1500 0.0001\n",
      "Training error:3.670643136929812 0.9922725894520033\n",
      "Testing error:20.318682881244325 0.7141699899094822\n",
      "\n",
      "Parameters: (200, 200) relu adam adaptive 1500 0.001\n",
      "Training error:3.667026341726779 0.9922878100502088\n",
      "Testing error:18.22828029614229 0.7699574800283359\n",
      "\n",
      "Parameters: (200, 200) relu adam adaptive 1500 0.01\n",
      "Training error:2.6774037216513373 0.9958887168933943\n",
      "Testing error:21.004421459498026 0.6945513795125129\n",
      "\n",
      "Parameters: (200, 200) relu adam adaptive 1500 0.1\n",
      "Training error:4.173688195321394 0.9900094439594915\n",
      "Testing error:18.20145763108587 0.7706339907651047\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.0001\n",
      "Training error:4.653517740038537 0.9875802628101163\n",
      "Testing error:20.00032532332106 0.7230567145854174\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.001\n",
      "Training error:2.979544383004738 0.9949084574644277\n",
      "Testing error:17.06678257789931 0.7983398751030689\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.01\n",
      "Training error:2.8672934224420112 0.9952848671333772\n",
      "Testing error:21.657686242720363 0.6752562243896074\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.1\n",
      "Training error:5.422228056475827 0.9831381501400718\n",
      "Testing error:17.7706747762143 0.7813625477807818\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.0001\n",
      "Training error:2.9753886253411608 0.9949226505477649\n",
      "Testing error:21.708297531240806 0.673736680259079\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.001\n",
      "Training error:4.92382061698011 0.9860955407642589\n",
      "Testing error:22.228291621627235 0.6579190482624515\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.01\n",
      "Training error:3.7758723137489065 0.9918231833900464\n",
      "Testing error:19.699495936076207 0.7313251917381338\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.1\n",
      "Training error:4.368988491368098 0.9890525880798057\n",
      "Testing error:24.406430156850735 0.5875937457791955\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.0001\n",
      "Training error:5.102883720842565 0.9850658330286207\n",
      "Testing error:24.909086535945733 0.5704316031738463\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.001\n",
      "Training error:7.63174638287774 0.9665960736632463\n",
      "Testing error:24.967404963038167 0.568417793521039\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.01\n",
      "Training error:5.303354398119319 0.9838693837967688\n",
      "Testing error:23.787570729213886 0.6082428736081498\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.1\n",
      "Training error:8.264820783706222 0.9608243203588569\n",
      "Testing error:25.14104950628789 0.5623937393568227\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.0001\n",
      "Training error:5.464544391061854 0.9828739355194686\n",
      "Testing error:20.800210257517662 0.700461831361011\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.001\n",
      "Training error:6.190767938775625 0.9780194422768156\n",
      "Testing error:17.57386377680004 0.7861785691238059\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.01\n",
      "Training error:4.100901962394204 0.9903548623000693\n",
      "Testing error:17.871977101140327 0.7788627427270454\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.1\n",
      "Training error:3.3006386058990613 0.9937519340005884\n",
      "Testing error:17.266097602816643 0.7936021812190932\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.0001\n",
      "Training error:4.437530608755335 0.9887064005211816\n",
      "Testing error:18.775180849747024 0.7559465349338901\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.001\n",
      "Training error:3.2415290011981384 0.9939737175755136\n",
      "Testing error:18.280484960865003 0.768637938155324\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.01\n",
      "Training error:2.2133065381673553 0.9971904757038643\n",
      "Testing error:16.453393342935442 0.8125749304220963\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.1\n",
      "Training error:4.349096319971597 0.9891520491070679\n",
      "Testing error:22.869580907232564 0.6378961583834957\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.0001\n",
      "Training error:4.86352467988298 0.9864339970763212\n",
      "Testing error:17.80998015047177 0.7803943087314685\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.001\n",
      "Training error:3.0682045185673554 0.9946009385729254\n",
      "Testing error:18.605965366705604 0.7603258826807057\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.01\n",
      "Training error:3.786670573039441 0.9917763483106897\n",
      "Testing error:17.415662491367403 0.790010915816893\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.1\n",
      "Training error:4.124955855184858 0.990241383109923\n",
      "Testing error:20.887204927212867 0.6979510185763855\n",
      "\n",
      "Best parameters:\n",
      "RMSE: 16.453393342935442\n",
      "R2: 0.8125749304220963\n",
      "Parameters: ((300, 200), 'relu', 'adam', 'adaptive', 1500)\n"
     ]
    }
   ],
   "source": [
    "# Grid search for Paytm+Cash onehot using grid search\n",
    "best_parameters_paytm_onehot = grid_search(X_train_onehot, y_paytm_train_onehot, X_test_onehot, y_paytm_test_onehot, parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: (200, 200) relu adam adaptive 1500 0.0001\n",
      "Training error:6.4859146589398815 0.9946949716701632\n",
      "Testing error:78.08379318453386 0.28304380060761025\n",
      "\n",
      "Parameters: (200, 200) relu adam adaptive 1500 0.001\n",
      "Training error:6.00633816653764 0.995450488076458\n",
      "Testing error:65.94785091501507 0.48858658686174095\n",
      "\n",
      "Parameters: (200, 200) relu adam adaptive 1500 0.01\n",
      "Training error:9.434827579762153 0.9887743064223632\n",
      "Testing error:61.70363098706068 0.5522946732713496\n",
      "\n",
      "Parameters: (200, 200) relu adam adaptive 1500 0.1\n",
      "Training error:28.30443245820908 0.898969116751845\n",
      "Testing error:59.308849298480524 0.5863721092420566\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.0001\n",
      "Training error:8.259432986389887 0.9913970833504573\n",
      "Testing error:50.69555551827309 0.6977887743824619\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.001\n",
      "Training error:8.912647141534876 0.989982515637762\n",
      "Testing error:61.08724871469441 0.561194613085017\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.01\n",
      "Training error:7.286783523847619 0.9933039762887432\n",
      "Testing error:67.6619872638372 0.4616554540437493\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.1\n",
      "Training error:6.421125094338028 0.9948004290451019\n",
      "Testing error:57.77707470726624 0.6074618076041983\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.0001\n",
      "Training error:8.733284823739224 0.9903816517799672\n",
      "Testing error:76.03205097544388 0.3202264988260638\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.001\n",
      "Training error:7.77559850197668 0.9923754730758542\n",
      "Testing error:62.90363496266642 0.5347115155657509\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.01\n",
      "Training error:10.330150940982215 0.9865426799182601\n",
      "Testing error:57.1764016135735 0.6155813416559752\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.1\n",
      "Training error:7.342403085402077 0.9932013655088844\n",
      "Testing error:53.93031740973258 0.6579916005624549\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error:16.874251520764606 0.9640917463758261\n",
      "Testing error:77.32241564451297 0.2969573920489814\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.001\n",
      "Training error:18.22260192829021 0.9581239197120336\n",
      "Testing error:64.1728998199313 0.5157449612654338\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.01\n",
      "Training error:26.865023993755194 0.9089835875595299\n",
      "Testing error:67.2392897590799 0.4683607285857657\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error:11.453701746244654 0.9834561346255432\n",
      "Testing error:51.495367207804094 0.6881777232630568\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.0001\n",
      "Training error:6.218111130325315 0.9951240167334876\n",
      "Testing error:65.37568158585326 0.49742222558217\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.001\n",
      "Training error:6.187554160684991 0.995171821983058\n",
      "Testing error:76.06405133881569 0.31965417238032967\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.01\n",
      "Training error:6.834885104845157 0.9941087468582002\n",
      "Testing error:68.75166273492057 0.4441760821042525\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.1\n",
      "Training error:5.897740546010982 0.9956135157559632\n",
      "Testing error:62.21734816674024 0.5448088469765138\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.0001\n",
      "Training error:7.399306575760048 0.9930955785805309\n",
      "Testing error:73.28961881911495 0.36838018629656366\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.001\n",
      "Training error:5.208888041454672 0.9965783522865143\n",
      "Testing error:72.91972901028109 0.37473961825678603\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.01\n",
      "Training error:9.719820491725958 0.9880858864152626\n",
      "Testing error:72.75205478899434 0.37761180422243223\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.1\n",
      "Training error:7.160391018690811 0.9935342527193591\n",
      "Testing error:60.97179352904806 0.5628517340858042\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.0001\n",
      "Training error:5.152194494026463 0.9966524293935467\n",
      "Testing error:79.22055148026773 0.26201668660131616\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.001\n",
      "Training error:6.9768658909908785 0.9938614471726459\n",
      "Testing error:63.462641228322916 0.5264050038331176\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.01\n",
      "Training error:8.212455764812772 0.9914946667570905\n",
      "Testing error:71.40437079071417 0.4004568954375227\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.1\n",
      "Training error:5.318298319955222 0.9964331024399474\n",
      "Testing error:78.27038650652356 0.2796131506196229\n",
      "\n",
      "Best parameters:\n",
      "RMSE: 50.69555551827309\n",
      "R2: 0.6977887743824619\n",
      "Parameters: ((200, 100), 'relu', 'adam', 'adaptive', 1500)\n"
     ]
    }
   ],
   "source": [
    "# Grid search for Coupons onehot using grid search\n",
    "best_parameters_coupons_onehot = grid_search(X_train_onehot, y_coupons_train_onehot, X_test_onehot, y_coupons_test_onehot, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: (200, 200) relu adam adaptive 1500 0.0001\n",
      "Training error:42.65866424683448 -0.04367231461119325\n",
      "Testing error:38.954438523047045 -0.05058360250929539\n",
      "\n",
      "Parameters: (200, 200) relu adam adaptive 1500 0.001\n",
      "Training error:43.71848590865923 -0.09617497633620053\n",
      "Testing error:38.77518705305782 -0.04093718573428262\n",
      "\n",
      "Parameters: (200, 200) relu adam adaptive 1500 0.01\n",
      "Training error:41.66728182249278 0.004273653902776675\n",
      "Testing error:37.91236858733494 0.0048728938728261895\n",
      "\n",
      "Parameters: (200, 200) relu adam adaptive 1500 0.1\n",
      "Training error:41.685304971230025 0.0034120663672894125\n",
      "Testing error:38.132115132330874 -0.006696390373986727\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.0001\n",
      "Training error:41.729880902206986 0.0012795361073545397\n",
      "Testing error:38.162252451679464 -0.008288283171232091\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.001\n",
      "Training error:41.03462712489404 0.03428130002257168\n",
      "Testing error:37.07532938761807 0.0483291730959704\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.01\n",
      "Training error:42.17070336005259 -0.019932304502888964\n",
      "Testing error:38.838312060351065 -0.04432918246500828\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.1\n",
      "Training error:41.4912899406013 0.012667274125922834\n",
      "Testing error:36.66869777451443 0.0690900030005962\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.0001\n",
      "Training error:42.78508082196368 -0.04986720967359948\n",
      "Testing error:39.6903445155907 -0.0906526462748789\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.001\n",
      "Training error:38.92606997374404 0.13097798970701957\n",
      "Testing error:34.47203598516338 0.17728277701086015\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.01\n",
      "Training error:41.7020524048785 0.0026111297763484753\n",
      "Testing error:37.92004163899134 0.004470047273573918\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.1\n",
      "Training error:41.18253958443334 0.02730673827686725\n",
      "Testing error:38.07702433790968 -0.0037896729568320797\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.0001\n",
      "Training error:41.232040270807076 0.024967012670459088\n",
      "Testing error:37.310103517179634 0.03623837819872733\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.001\n",
      "Training error:41.897829474471116 -0.006775661168828329\n",
      "Testing error:38.14892373759507 -0.007584087875434964\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.01\n",
      "Training error:41.62595434594531 0.006247886335768893\n",
      "Testing error:37.95638276966546 0.0025609765723110245\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.1\n",
      "Training error:41.71988277626945 0.0017580487011096269\n",
      "Testing error:38.06056649326126 -0.002922134352703498\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.0001\n",
      "Training error:41.163159586535464 0.028221997902990403\n",
      "Testing error:37.59393570182141 0.021519198822337327\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.001\n",
      "Training error:41.611577308298486 0.006934224677799694\n",
      "Testing error:37.89067821083533 0.0060112298776971995\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.01\n",
      "Training error:42.32252592035387 -0.02728942515319277\n",
      "Testing error:37.56333393453173 0.023111533021775044\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.1\n",
      "Training error:39.538226107959694 0.10343037837062496\n",
      "Testing error:34.87854616757809 0.15776464461283501\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.0001\n",
      "Training error:41.211909833229214 0.025918847659732736\n",
      "Testing error:37.5659446837079 0.022975735736320946\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.001\n",
      "Training error:39.45569472425347 0.10716943855027872\n",
      "Testing error:35.10291780203418 0.14689368968293248\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.01\n",
      "Training error:41.39979372285224 0.0170169872732725\n",
      "Testing error:37.703565789889254 0.015804056513846643\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.1\n",
      "Training error:44.39499005673489 -0.13036209158820733\n",
      "Testing error:41.52776567400542 -0.19397119881475966\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.0001\n",
      "Training error:41.679162807292734 0.003705731269240009\n",
      "Testing error:37.99025554101807 0.0007799270066436437\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.001\n",
      "Training error:42.97564547074909 -0.059240249176433224\n",
      "Testing error:39.17149788010908 -0.06232420727341026\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.01\n",
      "Training error:42.436802157189625 -0.03284454066404785\n",
      "Testing error:38.667657188710834 -0.035171816675780176\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.1\n",
      "Training error:43.5473867553544 -0.08761166064771553\n",
      "Testing error:38.78414974831226 -0.041418456450426744\n",
      "\n",
      "Best parameters:\n",
      "RMSE: 34.47203598516338\n",
      "R2: 0.17728277701086015\n",
      "Parameters: ((100, 100), 'relu', 'adam', 'adaptive', 1500)\n"
     ]
    }
   ],
   "source": [
    "# Grid search for Paytm+Cash no onehot using grid search\n",
    "best_parameters_paytm_no_onehot = grid_search(X_train_no_onehot, y_paytm_train_no_onehot, X_test_no_onehot, y_paytm_test_no_onehot, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: (200, 200) relu adam adaptive 1500 0.0001\n",
      "Training error:69.90430251965783 0.3837554929399285\n",
      "Testing error:94.68677518015971 -0.05426422791395935\n",
      "\n",
      "Parameters: (200, 200) relu adam adaptive 1500 0.001\n",
      "Training error:76.80374354436351 0.2561077655281686\n",
      "Testing error:114.92406787337752 -0.5530763246419999\n",
      "\n",
      "Parameters: (200, 200) relu adam adaptive 1500 0.01\n",
      "Training error:70.07298207079981 0.38077790053089533\n",
      "Testing error:95.25679432301044 -0.06699588272769041\n",
      "\n",
      "Parameters: (200, 200) relu adam adaptive 1500 0.1\n",
      "Training error:73.3422570958776 0.32165006165613286\n",
      "Testing error:108.48466233907202 -0.3839089006717915\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.0001\n",
      "Training error:72.33717648327371 0.3401148522820756\n",
      "Testing error:91.81596765650102 0.008695105076890086\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.001\n",
      "Training error:70.09279402832942 0.38042770175644247\n",
      "Testing error:97.08743923404874 -0.10840100798676144\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.01\n",
      "Training error:71.71090534134888 0.3514915214026487\n",
      "Testing error:98.11419281457555 -0.13196888644457583\n",
      "\n",
      "Parameters: (200, 100) relu adam adaptive 1500 0.1\n",
      "Training error:69.973040853573 0.3825429653639747\n",
      "Testing error:99.96380378527242 -0.17505005223140047\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.0001\n",
      "Training error:75.67791489215833 0.27775663149204965\n",
      "Testing error:111.8198662914026 -0.4703094772848362\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.001\n",
      "Training error:71.26937179331456 0.3594528415631286\n",
      "Testing error:91.70487693760741 0.01109246916725859\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.01\n",
      "Training error:71.07084495911822 0.3630164673059477\n",
      "Testing error:98.04908010688082 -0.13046694059855035\n",
      "\n",
      "Parameters: (100, 100) relu adam adaptive 1500 0.1\n",
      "Training error:74.24738348414208 0.3048035359401716\n",
      "Testing error:109.87421182882673 -0.4195881480648873\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.0001\n",
      "Training error:72.88399576312972 0.330100589020231\n",
      "Testing error:98.50629409348122 -0.14103451342699236\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.001\n",
      "Training error:71.64976759123806 0.35259683301040756\n",
      "Testing error:102.19895036127721 -0.22818472048203864\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.01\n",
      "Training error:70.60264791520743 0.3713814012570963\n",
      "Testing error:98.27271496320832 -0.13562966367515839\n",
      "\n",
      "Parameters: (50, 50) relu adam adaptive 1500 0.1\n",
      "Training error:72.2562248770422 0.3415909638779555\n",
      "Testing error:103.7647965015396 -0.2661084193444898\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.0001\n",
      "Training error:72.44061063137745 0.338226377787474\n",
      "Testing error:92.0580439678101 0.0034609876263062\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.001\n",
      "Training error:70.41908214073005 0.37464594879238977\n",
      "Testing error:96.38236648982235 -0.09236050651120964\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.01\n",
      "Training error:72.46958248922587 0.33769693318105165\n",
      "Testing error:91.51136890136664 0.015261487501880389\n",
      "\n",
      "Parameters: (300, 300) relu adam adaptive 1500 0.1\n",
      "Training error:71.02690147598368 0.3638039244288941\n",
      "Testing error:102.45841005805924 -0.23442879524014626\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.0001\n",
      "Training error:71.15625348343342 0.36148457295071024\n",
      "Testing error:103.00547382704909 -0.24764614145117436\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.001\n",
      "Training error:72.17903331452139 0.34299697352878233\n",
      "Testing error:93.49634397728722 -0.02792180099144015\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.01\n",
      "Training error:75.17943500856563 0.2872399286334393\n",
      "Testing error:114.22997540779855 -0.5343731351473662\n",
      "\n",
      "Parameters: (300, 200) relu adam adaptive 1500 0.1\n",
      "Training error:75.38673527545772 0.2833037707254441\n",
      "Testing error:113.18791094452128 -0.5065061475732313\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.0001\n",
      "Training error:72.10381661883041 0.34436556620095427\n",
      "Testing error:106.33233677775287 -0.3295403910253458\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.001\n",
      "Training error:69.84991381276299 0.3847140520526695\n",
      "Testing error:95.11573662858369 -0.0638381753324524\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.01\n",
      "Training error:73.26793430853901 0.3230242029699504\n",
      "Testing error:91.57677792329999 0.013853273353474083\n",
      "\n",
      "Parameters: (400, 400) relu adam adaptive 1500 0.1\n",
      "Training error:76.9650074268645 0.2529806030560833\n",
      "Testing error:116.64281400314968 -0.5998777414311356\n",
      "\n",
      "Best parameters:\n",
      "RMSE: 91.51136890136664\n",
      "R2: 0.015261487501880389\n",
      "Parameters: ((300, 300), 'relu', 'adam', 'adaptive', 1500)\n"
     ]
    }
   ],
   "source": [
    "# Grid search for Coupons no onehot using grid search\n",
    "best_parameters_coupons_no_onehot = grid_search(X_train_no_onehot, y_coupons_train_no_onehot, X_test_no_onehot, y_coupons_test_no_onehot, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid search for Paytm+Cash using onehot\n",
    "# mlp_paytm = MLPRegressor()\n",
    "# clf_paytm = GridSearchCV(mlp_paytm, parameters, n_jobs=-1, verbose=10, cv=3, return_train_score=True)\n",
    "# clf_paytm.fit(X_train_onehot, y_paytm_train_onehot)\n",
    "# print('Best parameters for Paytm+Cash onehot: ', clf_paytm.best_params_)\n",
    "# print('Results for Paytm+Cash onehot: ', clf_paytm.cv_results_)\n",
    "\n",
    "# # Metrics\n",
    "# y_paytm_pred_onehot = clf_paytm.predict(X_test_onehot)\n",
    "# print('Paytm+Cash onehot Metrics:')\n",
    "# print('RMSE: ', np.sqrt(mean_squared_error(y_paytm_test_onehot, y_paytm_pred_onehot)))\n",
    "# print('R2 Score: ', r2_score(y_paytm_test_onehot, y_paytm_pred_onehot))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid search for Paytm+Cash using no onehot\n",
    "# mlp_paytm = MLPRegressor()\n",
    "# clf_paytm = GridSearchCV(mlp_paytm, parameters, n_jobs=-1, verbose=10, cv=3, return_train_score=True)\n",
    "# clf_paytm.fit(X_train_no_onehot, y_paytm_train_no_onehot)\n",
    "# print('Best parameters for Paytm+Cash no onehot: ', clf_paytm.best_params_)\n",
    "# print('Results for Paytm+Cash no onehot: ', clf_paytm.cv_results_)\n",
    "\n",
    "# # Metrics\n",
    "# y_paytm_pred_no_onehot = clf_paytm.predict(X_test_no_onehot)\n",
    "# print('Paytm+Cash no onehot Metrics:')\n",
    "# print('RMSE: ', np.sqrt(mean_squared_error(y_paytm_test_no_onehot, y_paytm_pred_no_onehot)))\n",
    "# print('R2 Score: ', r2_score(y_paytm_test_no_onehot, y_paytm_pred_no_onehot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid search for Coupons using onehot\n",
    "# mlp_coupons = MLPRegressor()\n",
    "# clf_coupons = GridSearchCV(mlp_coupons, parameters, n_jobs=-1, verbose=10, cv=3, return_train_score=True)\n",
    "# clf_coupons.fit(X_train_onehot, y_coupons_train_onehot)\n",
    "# print('Best parameters for Coupons onehot: ', clf_coupons.best_params_)\n",
    "# print('Results for Coupons onehot: ', clf_coupons.cv_results_)\n",
    "\n",
    "# # Metrics\n",
    "# y_coupons_pred_onehot = clf_coupons.predict(X_test_onehot)\n",
    "# print('Coupons onehot Metrics:')\n",
    "# print('RMSE: ', np.sqrt(mean_squared_error(y_coupons_test_onehot, y_coupons_pred_onehot)))\n",
    "# print('R2 Score: ', r2_score(y_coupons_test_onehot, y_coupons_pred_onehot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid search for Coupons using no onehot\n",
    "# mlp_coupons = MLPRegressor()\n",
    "# clf_coupons = GridSearchCV(mlp_coupons, parameters, n_jobs=-1, verbose=10, cv=3, return_train_score=True)\n",
    "# clf_coupons.fit(X_train_no_onehot, y_coupons_train_no_onehot)\n",
    "# print('Best parameters for Coupons no onehot: ', clf_coupons.best_params_)\n",
    "# print('Results for Coupons no onehot: ', clf_coupons.cv_results_)\n",
    "\n",
    "# # Metrics\n",
    "# print('Coupons no onehot Metrics:')\n",
    "# y_coupons_pred_no_onehot = clf_coupons.predict(X_test_no_onehot)\n",
    "# print('RMSE: ', np.sqrt(mean_squared_error(y_coupons_test_no_onehot, y_coupons_pred_no_onehot)))\n",
    "# print('R2 Score: ', r2_score(y_coupons_test_no_onehot, y_coupons_pred_no_onehot))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
